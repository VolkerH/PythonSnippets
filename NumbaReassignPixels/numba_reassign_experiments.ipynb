{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value reassignment in numpy -- perfomance comparison between numba loops and numpy LUT\n",
    "\n",
    "\n",
    "### Problem definition\n",
    "\n",
    "We want to address a simple problem. Given a numpy array **A** containing integer values, we want to create a numpy array **B**, in which all elements in **A** are replaced by a value map that maps integer values that are present in **A** to some target values (not necessarily integers).\n",
    "\n",
    "### Representing the mapping\n",
    "\n",
    "The mapping can be represented in several ways:\n",
    "\n",
    "1. Two vectors of the same length. One vector (`input_vals`) contains the source values and the other vector (`dest_vals`) contains the destination values. For each pixel in **A**, one needs to find the index `i` at which `input_vals[i] == A[pixel]`. The replacement value is then found at the same index position in `dest_vals`, i.e. we can assign `B[pixel]=dest_val[i]`. The two vectors can also be represented as a table with two columns or and array with two columns if the input and output data types are identical. \n",
    "2. A lookup table **L** (represented as vector/array). For a given pixel value `A[pixel]` the pixel value is used as the index to the lookup table `B[pixel]=L[A[pixel]]`\n",
    "3. A hash table with lookup values. The idea is the same as in 2. but the representation is different(for example a `dict`).\n",
    "\n",
    "The different approaches each have their pros and cons:\n",
    "\n",
    "1. When using two vectors, we need to search the `input_vals` at each pixel to find the output pixel. So the complexity is `O(n_pixels) * O(n_different_input_values)`. We can implement a few speed-ups if we make assumptions about the input data, but the asymptotic complexity remains the same. The memory footprint depends only on the size of the input value and the number of different input values in the source image. This approach (looping over pixels) is not very fast to apply in numpy, therefore we will use numba in the examples below to speed up the loop.\n",
    "2. For the lookup table approach the complexity is always `O(n_pixels)` as the lookup takes constant time. However, the size of the lookup table depends on the maximum value of the lookup table, not on the number of different values. For many practical problems, that is not an issue but conceptually that is not very nice. This implementation can be implemented easily with numpy arrays, which make use of vectorization and are thus very fast.\n",
    "3. Implementing a LUT as a hash table (sparse array) does have the same complexity `O(n_pixels)` as the lookup is still happening in constant time. The LUT memory requirements for a hash table only scale with the number of different values in **A**. So in theory, this should be the best option. However, numpy does not implement sparse arrays, so we have to rely on python dictionaries for hashing, which is much less efficiently implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.48.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import skimage.segmentation\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a simple reassignment loop in pure python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reassign_pure_python(inarr, resarr, invals, outvals):\n",
    "    \"\"\" simple reassignment, making no assumptions about the data\"\"\"\n",
    "    for i in range(len(inarr)):\n",
    "        for j in range(len(invals)):\n",
    "            if inarr[i] == invals[j]:\n",
    "                resarr[i] = outvals[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing this with numba is a simple matter of adding a decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nogil=True, nopython=True)\n",
    "def _reassign_simple(inarr, resarr, invals, outvals):\n",
    "    \"\"\" simple reassignment, making no assumptions about the data\"\"\"\n",
    "    for i in range(len(inarr)):\n",
    "        for j in range(len(invals)):\n",
    "            if inarr[i] == invals[j]:\n",
    "                resarr[i] = outvals[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every pixel can be processed independently, so we give numba some hints about\n",
    "parralelization by using `numba.prange` instead of `range` and by setting `parallel=True` in the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nogil=True, nopython=True, parallel=True)\n",
    "def _reassign_parallel(inarr, resarr, invals, outvals):\n",
    "    \"\"\" simple reassignment, with some hints for paralllelization\"\"\"\n",
    "    for i in numba.prange(len(inarr)):\n",
    "        for j in range(len(invals)):\n",
    "            if inarr[i] == invals[j]:\n",
    "                resarr[i] = outvals[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a few optimizations if we make assumptions about the type of data we process.\n",
    "In image analysis, one often comes across so-called label images, where each integer value represents an object. Often, most of the image area will be background, with some connected components as foreground. We add some simple mechanism to speed up the lookup for the background pixel and to cache the most recent lookup.\n",
    "It also makes sense to pass in the vectors for input and output values sorted by the frequency of the values if available (most frequent values first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nogil=True, nopython=True)    \n",
    "def _reassign_optimized(inarr, resarr, invals, outvals):\n",
    "    \"\"\" optimized reassignment, making the following assumptions\n",
    "    about the data:\n",
    "    1. zeroth element of the invals is the most frequent value (background\n",
    "    label)\n",
    "    2. array contains connected components which often results in\n",
    "    neighbouring pixels having the same value. \n",
    "    \"\"\"\n",
    "    zeroval = invals[0]\n",
    "    zeroval_replace = outvals[0]\n",
    "    lastval = zeroval\n",
    "    lastval_replace = zeroval_replace\n",
    "    for i in range(len(inarr)):\n",
    "        if inarr[i] == lastval:\n",
    "            resarr[i] == lastval_replace\n",
    "        elif inarr[i] == zeroval:\n",
    "            resarr[i] == zeroval_replace\n",
    "        else: \n",
    "            for j in range(len(invals)):\n",
    "                if inarr[i] == invals[j]:\n",
    "                    resarr[i] = outvals[j]\n",
    "                    lastval = invals[j]\n",
    "                    lastval_replace = outvals[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reassign_dict(inarr, resarr, invals, outvals):\n",
    "    @numba.jit(nogil=True, nopython=True, parallel=True)\n",
    "    def _reassign_dict_inner(inarr, resarr, lut_dict):\n",
    "        \"\"\" simple reassignment, with some hints for paralllelization\"\"\"\n",
    "        for i in numba.prange(len(inarr)):\n",
    "            resarr[i] = lut_dict[inarr[i]]\n",
    "    # turn the inval/outval vectors into a dict\n",
    "    lut = dict(zip(list(invals),list(outvals)))\n",
    "    _reassign_dict_inner(inarr, resarr, lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: currently this is hardcoded to int64 -> int64\n",
    "# need to check out how to automatically\n",
    "# create the correct numba types for the numba.typed.Dict\n",
    "# from numpy.dtypes\n",
    "from numba.typed import Dict\n",
    "from numba import types\n",
    "@numba.jit(nogil=True, nopython=True, parallel=True)\n",
    "def _reassign_dict(inarr, resarr, invals, outvals):\n",
    "    lut = Dict.empty(\n",
    "        key_type=types.int64,\n",
    "        value_type=types.int64)\n",
    "    for key, value in zip(invals,outvals):\n",
    "        lut[key]=value\n",
    "    for i in numba.prange(len(inarr)):\n",
    "        resarr[i] = lut[inarr[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also compare with cython\n",
    "\n",
    "Let's also compare with cython. Instead of a dictionary we use a `map` from the `C++ STL` as a hash table to do the LUT.\n",
    "\n",
    "Note that we cannot name the function `_reassign_cython` as function names starting with an underscore don't seem to be visible outside the cython cell\n",
    "\n",
    "## TODO: fused type\n",
    "\n",
    "I have tried to use fused types so that I don't have to define this differently for different output types. However, when I ude the fused `out_ype` to declare the views into the numpy arrays in `reassign_cython` I get cython compilation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "\n",
    "from libcpp.map cimport map\n",
    "from cython.parallel import prange\n",
    "import numpy as np\n",
    "cimport cython\n",
    "\n",
    "# TODO try with fused types\n",
    "ctypedef fused out_type:\n",
    "    int\n",
    "    double\n",
    "    long long\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing\n",
    "cpdef int _reassign_cython_inner(int[:] inarr, out_type[:] outarr, int[:] inval, int[:] outval) nogil:\n",
    "    # build the map from the input and output vectors\n",
    "    cdef size_t i, n_map, n_array\n",
    "    cdef map[int, out_type] lut\n",
    "    n_map = inval.shape[0]\n",
    "    for i in range(n_map):\n",
    "        lut[inval[i]] = outval[i]\n",
    "    # apply the map to the array\n",
    "    n_array = inarr.shape[0]\n",
    "    # The prange option gave some compilation warnings\n",
    "    #  \"Unsigned index type not allowed before OpenMP 3.0\"\n",
    "    # and didn't seem to be any faster\n",
    "    # for i in prange(n_array, nogil=True): # \n",
    "    for i in range(n_array):\n",
    "        outarr[i] = lut[inarr[i]]\n",
    "\n",
    "# note ... if we call the following function _reassign_cython\n",
    "# it is not visible in the notebook outside the cython cell\n",
    "cpdef reassign_cython(inarr, outarr, inval, outval):\n",
    "    cdef int [:] inval_view = inval\n",
    "    cdef int [:] outval_view = outval\n",
    "    cdef int [:] inarr_view = inarr.reshape(-1)\n",
    "    cdef int [:] outarr_view = outarr.reshape(-1)\n",
    "    _reassign_cython_inner(inarr_view, outarr_view, inval_view, outval_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython with `unordered_map`\n",
    "\n",
    "@jni pointed out to me that `map` from the `C++` STL is not implemented as a hash table (as I had wrongly assumed) but as a red-black tree. To get a hash table we need an `unordered_map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "\n",
    "from libcpp.unordered_map cimport unordered_map\n",
    "from cython.parallel import prange\n",
    "import numpy as np\n",
    "cimport cython\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing\n",
    "cdef int _reassign_cython_inner(long[:] inarr, long[:] outarr, long[:] inval, long[:] outval) nogil:\n",
    "    # build the map from the input and output vectors\n",
    "    cdef size_t i, n_map, n_array\n",
    "    cdef unordered_map[long, long] lut\n",
    "    n_map = inval.shape[0]\n",
    "    for i in range(n_map):\n",
    "        lut[inval[i]] = outval[i]\n",
    "    # apply the map to the array\n",
    "    n_array = inarr.shape[0]\n",
    "    # The prange option gave some compilation warnings\n",
    "    #  \"Unsigned index type not allowed before OpenMP 3.0\"\n",
    "    # and didn't seem to be any faster\n",
    "    # for i in prange(n_array, nogil=True): #\n",
    "    for i in range(n_array):\n",
    "        outarr[i] = lut[inarr[i]]\n",
    "\n",
    "# note ... if we call the following function _reassign_cython\n",
    "# it is not visible in the notebook outside the cython cell\n",
    "cpdef reassign_cython_hashmap(inarr, outarr, inval, outval):\n",
    "    cdef long [:] inval_view = inval\n",
    "    cdef long [:] outval_view = outval\n",
    "    cdef long [:] inarr_view = inarr.reshape(-1)\n",
    "    cdef long [:] outarr_view = outarr.reshape(-1)\n",
    "    _reassign_cython_inner(inarr_view, outarr_view, inval_view, outval_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a wrapper function that checks the input values and types, gives a flattened view of the input array and allocates space for an output array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign(input_arr, input_vals, output_vals, _reassign, inplace=False ):\n",
    "    \"\"\"\n",
    "    input_arr: input array (np.ndarray)\n",
    "    input_vals: 1d array of input values (integer)\n",
    "    output_vals: 1d array of output values\n",
    "    _reassign: function that does the actual reassigment\n",
    "    inplace: whether the reassignment should happen inplace\n",
    "    \"\"\"\n",
    "\n",
    "    assert issubclass(input_arr.dtype.type, np.integer), \"Reassignment only possible for integer types\"\n",
    "    assert issubclass(input_vals.dtype.type, np.integer), \"Reassignment only possible for integer types\"\n",
    "    assert input_vals.ndim == 1, \"input_vals must be a 1D array\"\n",
    "    assert input_vals.shape == output_vals.shape, \"output_vals must have the same shape as input_vals\"\n",
    "\n",
    "    # We want to reshape to 1D to make the numba loop as simple\n",
    "    # as possible\n",
    "    orig_shape = input_arr.shape\n",
    "    # numpy doc for ravel says \n",
    "    # \"When a view is desired in as many cases as possible, \n",
    "    # arr.reshape(-1) may be preferable.\"\n",
    "    input_arr = input_arr.reshape(-1) \n",
    "    \n",
    "    if inplace:\n",
    "        if input_vals.dtype == output_vals.dtype:\n",
    "            out_arr = input_arr\n",
    "        else:\n",
    "            raise TypeError(\"input_vals and output_vals dtypes must match for inplace operation\")\n",
    "    else:\n",
    "        out_arr = np.empty_like(input_arr, dtype=output_vals.dtype)\n",
    "\n",
    "    _reassign(input_arr, out_arr, input_vals, output_vals)\n",
    "    return out_arr.reshape(orig_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets implement something that does essentially the same as `skimage.segmentation.relabel_sequential`. This is a common operation on label images, e.g. after some filtering step that removes some labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_sequential(label, _reassign, inplace=False, sort=False):\n",
    "    unique_vals, counts = np.unique(label, return_counts=True)\n",
    "    sequential_vals = np.empty_like(unique_vals, label.dtype)\n",
    "    sequential_vals[:] = np.arange(len(unique_vals))\n",
    "    # sort such that largest counts are first for the value \n",
    "    # lookup. This is an optimization for reassign.\n",
    "    if sort:\n",
    "        idx = np.argsort(counts)[::-1] \n",
    "        sequential_vals = sequential_vals[idx].copy()\n",
    "        unique_vals = unique_vals[idx].copy()\n",
    "    relabeled = reassign(label, unique_vals, sequential_vals, _reassign, inplace=inplace)\n",
    "    return relabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some test data. Note that such random data is the worst case, where none of the assumptions for optimization will hold (no connected components, background is not the most common pixel type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelarr = np.random.randint(0,10000, size=(1000,1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the different implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.8 ms ± 689 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# use skimage.segmentation.relabel_sequential as baseline\n",
    "# that uses numpy arrays as LUTs\n",
    "%timeit relabeled = skimage.segmentation.relabel_sequential(labelarr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.43 s ± 73.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# simple loop with numba jit \n",
    "%timeit relabeled = relabel_sequential(labelarr, _reassign_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 s ± 56.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# simple loop with numba jit and parallelization \n",
    "%timeit relabeled = relabel_sequential(labelarr, _reassign_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.73 s ± 184 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# simple loop with optimizations for connected components\n",
    "# (not expected to perform better on random data)\n",
    "%timeit relabeled = relabel_sequential(labelarr, _reassign_optimized, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3 ms ± 3.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# simple loop with LUT implemented as dictionary\n",
    "%timeit relabeled = relabel_sequential(labelarr, _reassign_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Cython implementation\n",
    "%timeit relabeled = relabel_sequential(labelarr, reassign_cython)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.7 ms ± 1.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Cython implementation\n",
    "%timeit relabeled = relabel_sequential(labelarr, reassign_cython_hashmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally the pure python implementation\n",
    "# I interrupted this after several minutes (!!!) as I couldn't bear waiting\n",
    "#%timeit relabeled = relabel_sequential(labelarr, _reassign_pure_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary conclusion:\n",
    "\n",
    "* numpy LUTs as in `skimage.segmentation.relabel_sequential` perform fastest,\n",
    "* for a large number of objects and random label locations (no connected components), the simple numba loop is significantly slower than numpy LUTs,\n",
    "* numba loop with hash table LUT (dictionary) performance is similar order of magnitude as numpy LUTs (mostly a factor of two, pretty independent of input array size and number of labels ... variation of sizes not shown here)\n",
    "* cython loop with hash table implemented as C++ STL unordered map (hash table) performance lies inbetween numpy LUT and numba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* automatically create the correct numba.typed.Dict for different input/output dtypes\n",
    "* get fused types working in cython\n",
    "* try to parallelize cython (initilly changing the range to prange in the loop didn't make a huge difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
